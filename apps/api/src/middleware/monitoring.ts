import { Request, Response, NextFunction } from 'fastify';\nimport { pennyMonitoring } from '@penny/monitoring';\nimport { performance } from 'perf_hooks';\n\n// Extend the Request type to include monitoring properties\ndeclare module 'fastify' {\n  interface FastifyRequest {\n    startTime?: number;\n    monitoringContext?: {\n      traceId?: string;\n      spanId?: string;\n      tenantId?: string;\n      userId?: string;\n    };\n  }\n}\n\nexport interface MonitoringConfig {\n  enableMetrics?: boolean;\n  enableTracing?: boolean;\n  enableLogging?: boolean;\n  enableAlerting?: boolean;\n  excludePaths?: string[];\n  slowRequestThreshold?: number;\n  errorAlertThreshold?: number;\n}\n\n/**\n * HTTP Request Monitoring Middleware\n */\nexport const createHttpMonitoringMiddleware = (config: MonitoringConfig = {}) => {\n  const {\n    enableMetrics = true,\n    enableTracing = true,\n    enableLogging = true,\n    enableAlerting = true,\n    excludePaths = ['/health', '/metrics', '/ping'],\n    slowRequestThreshold = 1000, // 1 second\n    errorAlertThreshold = 100 // Alert after 100 errors\n  } = config;\n\n  const monitoring = pennyMonitoring.getMonitoring();\n  const metrics = pennyMonitoring.getMetrics();\n  const logging = pennyMonitoring.getLogging();\n  const tracing = pennyMonitoring.getTracing();\n  const alerting = pennyMonitoring.getAlerting();\n\n  return async (request: any, reply: any, next: NextFunction) => {\n    const startTime = performance.now();\n    const path = request.url.split('?')[0];\n    \n    // Skip monitoring for excluded paths\n    if (excludePaths.includes(path)) {\n      return next();\n    }\n\n    // Set monitoring context\n    request.startTime = startTime;\n    request.monitoringContext = {\n      tenantId: request.headers['x-tenant-id'] || request.query?.tenantId,\n      userId: request.user?.id || request.headers['x-user-id']\n    };\n\n    // Start tracing span if enabled\n    let span: any = null;\n    if (enableTracing) {\n      span = tracing.traceHttpRequest(request, reply);\n      if (span) {\n        const spanContext = span.spanContext();\n        request.monitoringContext.traceId = spanContext.traceId;\n        request.monitoringContext.spanId = spanContext.spanId;\n      }\n    }\n\n    // Increment active requests metric\n    if (enableMetrics) {\n      metrics.recordApiCall(\n        path,\n        request.monitoringContext.tenantId || 'unknown',\n        request.monitoringContext.userId\n      );\n    }\n\n    // Handle response completion\n    const onResponse = () => {\n      const duration = performance.now() - startTime;\n      const statusCode = reply.statusCode || 200;\n      \n      try {\n        // Record metrics\n        if (enableMetrics) {\n          metrics.recordHttpRequest(\n            request.method,\n            path,\n            statusCode,\n            duration,\n            request.monitoringContext?.tenantId\n          );\n\n          // Record error metrics\n          if (statusCode >= 400) {\n            const severity = statusCode >= 500 ? 'high' : 'medium';\n            metrics.recordError('http', 'api-service', severity);\n          }\n        }\n\n        // Log request\n        if (enableLogging) {\n          logging.logHttpRequest(request, reply, duration);\n        }\n\n        // Alert on slow requests\n        if (enableAlerting && duration > slowRequestThreshold) {\n          alerting.sendAlert({\n            name: 'Slow HTTP Request',\n            severity: duration > slowRequestThreshold * 2 ? 'high' : 'medium',\n            message: `Request to ${path} took ${duration.toFixed(2)}ms`,\n            metadata: {\n              method: request.method,\n              path,\n              duration,\n              statusCode,\n              tenantId: request.monitoringContext?.tenantId,\n              userId: request.monitoringContext?.userId\n            }\n          });\n        }\n      } catch (error) {\n        logging.error('Monitoring middleware error', { error: error.message });\n      }\n    };\n\n    // Attach response handler\n    reply.raw.on('finish', onResponse);\n\n    next();\n  };\n};\n\n/**\n * Error Monitoring Middleware\n */\nexport const createErrorMonitoringMiddleware = (config: MonitoringConfig = {}) => {\n  const {\n    enableLogging = true,\n    enableMetrics = true,\n    enableAlerting = true\n  } = config;\n\n  const monitoring = pennyMonitoring.getMonitoring();\n  const metrics = pennyMonitoring.getMetrics();\n  const logging = pennyMonitoring.getLogging();\n  const tracing = pennyMonitoring.getTracing();\n  const alerting = pennyMonitoring.getAlerting();\n\n  return async (error: Error, request: any, reply: any, next: NextFunction) => {\n    try {\n      const context = {\n        method: request.method,\n        url: request.url,\n        userAgent: request.headers['user-agent'],\n        ip: request.ip,\n        tenantId: request.monitoringContext?.tenantId,\n        userId: request.monitoringContext?.userId,\n        traceId: request.monitoringContext?.traceId,\n        spanId: request.monitoringContext?.spanId\n      };\n\n      // Log error\n      if (enableLogging) {\n        logging.logError(error, context);\n      }\n\n      // Record error metrics\n      if (enableMetrics) {\n        const errorType = error.name || 'UnknownError';\n        metrics.recordError('application', 'api-service', 'high');\n      }\n\n      // Record tracing exception\n      tracing.recordException(error);\n\n      // Send alert for critical errors\n      if (enableAlerting) {\n        const isCritical = error.message.includes('CRITICAL') || \n                          error.name === 'DatabaseError' ||\n                          error.name === 'SecurityError';\n        \n        if (isCritical) {\n          await alerting.sendApplicationAlert('api-service', error, context);\n        }\n      }\n    } catch (monitoringError) {\n      console.error('Error in error monitoring middleware:', monitoringError);\n    }\n\n    next(error);\n  };\n};\n\n/**\n * Performance Monitoring Middleware\n */\nexport const createPerformanceMonitoringMiddleware = () => {\n  const monitoring = pennyMonitoring.getMonitoring();\n  const metrics = pennyMonitoring.getMetrics();\n  const logging = pennyMonitoring.getLogging();\n\n  return async (request: any, reply: any, next: NextFunction) => {\n    const startMemory = process.memoryUsage();\n    const startCpu = process.cpuUsage();\n    \n    const onResponse = () => {\n      const endMemory = process.memoryUsage();\n      const endCpu = process.cpuUsage(startCpu);\n      const duration = performance.now() - request.startTime;\n      \n      // Log performance metrics\n      logging.logPerformanceMetric('request_memory_delta', endMemory.heapUsed - startMemory.heapUsed, 'bytes', {\n        method: request.method,\n        path: request.url.split('?')[0],\n        duration\n      });\n\n      logging.logPerformanceMetric('request_cpu_time', endCpu.user + endCpu.system, 'microseconds', {\n        method: request.method,\n        path: request.url.split('?')[0],\n        duration\n      });\n    };\n\n    reply.raw.on('finish', onResponse);\n    next();\n  };\n};\n\n/**\n * Database Query Monitoring Wrapper\n */\nexport const monitorDatabaseQuery = async <T>(\n  operation: string,\n  query: string,\n  executor: () => Promise<T>\n): Promise<T> => {\n  const monitoring = pennyMonitoring.getMonitoring();\n  return monitoring.monitorDatabaseOperation(operation, query, executor);\n};\n\n/**\n * AI Model Call Monitoring Wrapper\n */\nexport const monitorAIModelCall = async <T>(\n  provider: string,\n  model: string,\n  tokens: { input: number; output: number },\n  executor: () => Promise<T>\n): Promise<T> => {\n  const monitoring = pennyMonitoring.getMonitoring();\n  return monitoring.monitorAIModelCall(provider, model, tokens, executor);\n};\n\n/**\n * Tool Execution Monitoring Wrapper\n */\nexport const monitorToolExecution = async <T>(\n  toolName: string,\n  parameters: Record<string, any>,\n  tenantId: string,\n  executor: () => Promise<T>\n): Promise<T> => {\n  const monitoring = pennyMonitoring.getMonitoring();\n  return monitoring.monitorToolExecution(toolName, parameters, tenantId, executor);\n};\n\n/**\n * Business Operation Monitoring Wrapper\n */\nexport const monitorBusinessOperation = async <T>(\n  operation: string,\n  executor: () => Promise<T>,\n  metadata?: Record<string, any>\n): Promise<T> => {\n  const monitoring = pennyMonitoring.getMonitoring();\n  return monitoring.monitorBusinessOperation(operation, executor, metadata);\n};\n\n/**\n * Rate Limiting with Monitoring\n */\nexport const createRateLimitingMiddleware = (options: {\n  windowMs: number;\n  max: number;\n  keyGenerator?: (request: any) => string;\n}) => {\n  const { windowMs, max, keyGenerator = (req) => req.ip } = options;\n  const requests = new Map<string, { count: number; resetTime: number }>();\n  const metrics = pennyMonitoring.getMetrics();\n  const alerting = pennyMonitoring.getAlerting();\n\n  return async (request: any, reply: any, next: NextFunction) => {\n    const key = keyGenerator(request);\n    const now = Date.now();\n    const windowStart = now - windowMs;\n    \n    // Clean up old entries\n    for (const [k, v] of requests.entries()) {\n      if (v.resetTime < now) {\n        requests.delete(k);\n      }\n    }\n    \n    const current = requests.get(key) || { count: 0, resetTime: now + windowMs };\n    \n    if (current.count >= max) {\n      // Rate limit exceeded\n      metrics.recordError('rate_limit', 'api-service', 'medium');\n      \n      // Alert if too many rate limit violations\n      if (current.count === max + 10) { // Alert after 10 additional attempts\n        await alerting.sendSecurityAlert('Rate Limit Exceeded', {\n          key,\n          attempts: current.count,\n          window: windowMs,\n          ip: request.ip,\n          userAgent: request.headers['user-agent']\n        });\n      }\n      \n      reply.status(429).send({\n        error: 'Too Many Requests',\n        retryAfter: Math.ceil((current.resetTime - now) / 1000)\n      });\n      return;\n    }\n    \n    current.count++;\n    requests.set(key, current);\n    \n    next();\n  };\n};\n\n/**\n * Health Check Endpoint\n */\nexport const createHealthCheckEndpoint = () => {\n  const health = pennyMonitoring.getHealth();\n  \n  return async (request: any, reply: any) => {\n    const healthData = health.getOverallHealth();\n    const systemHealth = await health.getSystemHealth();\n    \n    const status = healthData.status === 'healthy' ? 200 : \n                  healthData.status === 'degraded' ? 200 : 503;\n    \n    reply.status(status).send({\n      status: healthData.status,\n      timestamp: new Date().toISOString(),\n      service: 'penny-api',\n      version: process.env.npm_package_version || '1.0.0',\n      uptime: process.uptime(),\n      system: systemHealth,\n      checks: healthData.checks.map(check => ({\n        name: check.name,\n        status: check.status,\n        message: check.message,\n        responseTime: check.responseTime\n      })),\n      summary: healthData.summary\n    });\n  };\n};\n\n/**\n * Metrics Endpoint\n */\nexport const createMetricsEndpoint = () => {\n  const metrics = pennyMonitoring.getMetrics();\n  \n  return async (request: any, reply: any) => {\n    const prometheusMetrics = await metrics.getMetrics();\n    reply.header('Content-Type', 'text/plain; version=0.0.4; charset=utf-8');\n    reply.send(prometheusMetrics);\n  };\n};\n\nexport {\n  pennyMonitoring\n};"